{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### migrate code from tensorflow v1 to v2: \n",
    "# !tf_upgrade_v2 \\\n",
    "#   --infile class_DeepLongitudinal-Original.py \\\n",
    "#   --outfile class_DeepLongitudinal-Original_v2.py\n",
    "\n",
    "# !tf_upgrade_v2 \\\n",
    "#   --infile utils_network-Original.py \\\n",
    "#   --outfile utils_network-Original_v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_EPSILON = 1e-08\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "from tf_slim.layers import layers as _layers\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    '''\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    '''\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set prediction time window (t) and evaluation time (delta t) for C-index and Brier-Score)\n",
    "pred_time = list(range(16,33,1)) # prediction time (in months)\n",
    "eval_time = list(range(1))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Dataset\n",
    "#####      - Users must prepare dataset in csv format and modify 'import_data.py' following our examplar 'PBC2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/data_longi_ascvd_for_dynamic_deephit.csv')\n",
    "\n",
    "trainingid_all = pd.read_csv('./data/all_training_set_ID.csv')\n",
    "validationid_all = pd.read_csv('./data/all_validation_set_ID.csv')\n",
    "testingid_all = pd.read_csv('./data/all_testing_set_ID.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>event</th>\n",
       "      <th>exam_year</th>\n",
       "      <th>time</th>\n",
       "      <th>AGE_Y0</th>\n",
       "      <th>MALE</th>\n",
       "      <th>RACEBLACK</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>DIAB</th>\n",
       "      <th>HBM</th>\n",
       "      <th>HDL</th>\n",
       "      <th>SBP</th>\n",
       "      <th>SMKNW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100033323702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.134155</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100033323702</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32.134155</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100033323702</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>32.134155</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100033323702</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>32.134155</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100033323702</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>32.134155</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201</th>\n",
       "      <td>416817227898</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31.770021</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20202</th>\n",
       "      <td>416817227898</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>31.770021</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20203</th>\n",
       "      <td>416817227898</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>31.770021</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20204</th>\n",
       "      <td>416817227898</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>31.770021</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20205</th>\n",
       "      <td>416817227898</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>31.770021</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20206 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  event  exam_year       time  AGE_Y0  MALE  RACEBLACK  \\\n",
       "0      100033323702      0          0  32.134155      22     1          0   \n",
       "1      100033323702      0          2  32.134155      22     1          0   \n",
       "2      100033323702      0          5  32.134155      22     1          0   \n",
       "3      100033323702      0          7  32.134155      22     1          0   \n",
       "4      100033323702      0         15  32.134155      22     1          0   \n",
       "...             ...    ...        ...        ...     ...   ...        ...   \n",
       "20201  416817227898      0          2  31.770021      22     1          1   \n",
       "20202  416817227898      0          5  31.770021      22     1          1   \n",
       "20203  416817227898      0          7  31.770021      22     1          1   \n",
       "20204  416817227898      0         10  31.770021      22     1          1   \n",
       "20205  416817227898      0         15  31.770021      22     1          1   \n",
       "\n",
       "       CHOL  DIAB  HBM  HDL    SBP  SMKNW  \n",
       "0       231     0    0   42  117.0      1  \n",
       "1       187     0    0   46  116.0      1  \n",
       "2       234     0    0   52  105.0      0  \n",
       "3       216     0    0   44  115.0      0  \n",
       "4       214     0    0   42  107.0      0  \n",
       "...     ...   ...  ...  ...    ...    ...  \n",
       "20201   203     0    0   56  102.0      1  \n",
       "20202   204     0    0   43  133.0      1  \n",
       "20203   170     0    0   47  133.0      1  \n",
       "20204   179     0    0   47  112.0      0  \n",
       "20205   223     0    0   41  106.0      1  \n",
       "\n",
       "[20206 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_mode                   = 'PBC2' \n",
    "data_mode                   = 'CARDIA_ASCVD' \n",
    "seed                        = 1234\n",
    "\n",
    "##### IMPORT DATASET\n",
    "'''\n",
    "    num_Category            = max event/censoring time * 1.2\n",
    "    num_Event               = number of evetns i.e. len(np.unique(label))-1\n",
    "    max_length              = maximum number of measurements\n",
    "    x_dim                   = data dimension including delta (1 + num_features)\n",
    "    x_dim_cont              = dim of continuous features\n",
    "    x_dim_bin               = dim of binary features\n",
    "    mask1, mask2, mask3     = used for cause-specific network (FCNet structure)\n",
    "'''\n",
    "\n",
    "# (x_dim, x_dim_cont, x_dim_bin), (data, time, label), (mask1, mask2, mask3), (data_mi) = impt.import_dataset(norm_mode = 'standard')\n",
    "\n",
    "\n",
    "\n",
    "(x_dim, x_dim_cont, x_dim_bin), (data, time, label), (mask1, mask2, mask3), (data_mi) = impt.import_dataset(df_ = df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "max_length                  = np.shape(data)[1]\n",
    "\n",
    "\n",
    "file_path = '{}'.format(data_mode)\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3551, 6, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3551, 1, 39)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3551, 39)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3551, 6, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dim_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set Hyper-Parameters\n",
    "##### - Play with your own hyper-parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_in_mode                = 'ON' #{'ON', 'OFF'}\n",
    "boost_mode                  = 'ON' #{'ON', 'OFF'}\n",
    "\n",
    "##### HYPER-PARAMETERS\n",
    "new_parser = {'mb_size': 32,\n",
    "\n",
    "             'iteration_burn_in': 3000,\n",
    "             'iteration': 25000,\n",
    "\n",
    "             'keep_prob': 0.6,\n",
    "             'lr_train': 1e-4,\n",
    "\n",
    "             'h_dim_RNN': 100,\n",
    "             'h_dim_FC' : 100,\n",
    "             'num_layers_RNN':2,\n",
    "             'num_layers_ATT':2,\n",
    "             'num_layers_CS' :2,\n",
    "\n",
    "             'RNN_type':'LSTM', #{'LSTM', 'GRU'}\n",
    "\n",
    "             'FC_active_fn' : tf.nn.relu,\n",
    "             'RNN_active_fn': tf.nn.tanh,\n",
    "\n",
    "            'reg_W'         : 1e-5,\n",
    "            'reg_W_out'     : 0.,\n",
    "\n",
    "             'alpha' :1.0,\n",
    "             'beta'  :0.1,\n",
    "             'gamma' :1.0\n",
    "}\n",
    "\n",
    "\n",
    "# INPUT DIMENSIONS\n",
    "input_dims                  = { 'x_dim'         : x_dim,\n",
    "                                'x_dim_cont'    : x_dim_cont,\n",
    "                                'x_dim_bin'     : x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "# NETWORK HYPER-PARMETERS\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : new_parser['FC_active_fn'],\n",
    "                                'RNN_active_fn'     : new_parser['RNN_active_fn'],\n",
    "                               # 'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "                               \n",
    "                                'initial_W'         : tf.keras.initializers.glorot_normal(),\n",
    "\n",
    "                               \n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : new_parser['reg_W_out']\n",
    "                                 }\n",
    "\n",
    "\n",
    "mb_size           = new_parser['mb_size']\n",
    "iteration         = new_parser['iteration']\n",
    "iteration_burn_in = new_parser['iteration_burn_in']\n",
    "\n",
    "keep_prob         = new_parser['keep_prob']\n",
    "lr_train          = new_parser['lr_train']\n",
    "\n",
    "alpha             = new_parser['alpha']\n",
    "beta              = new_parser['beta']\n",
    "gamma             = new_parser['gamma']\n",
    "\n",
    "# SAVE HYPERPARAMETERS\n",
    "log_name = file_path + '/hyperparameters_log.txt'\n",
    "save_logging(new_parser, log_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1...\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:981: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From U:\\Hieu\\CARDIA_longi_project\\Dynamic-DeepHit-master\\class_DeepLongitudinal.py:22: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "BURN-IN TRAINING ...\n",
      "itr: 1000 | loss: 2.1242\n",
      "itr: 2000 | loss: 1.8200\n",
      "itr: 3000 | loss: 1.4469\n",
      "MAIN TRAINING ...\n",
      "itr: 1000 | loss: 2.0664\n",
      "itr: 2000 | loss: 1.4569\n",
      "updated.... average c-index = 0.5223\n",
      "itr: 3000 | loss: 1.6083\n",
      "updated.... average c-index = 0.5399\n",
      "itr: 4000 | loss: 1.6314\n",
      "itr: 5000 | loss: 1.3455\n",
      "updated.... average c-index = 0.5401\n",
      "itr: 6000 | loss: 1.8566\n",
      "updated.... average c-index = 0.5472\n",
      "itr: 7000 | loss: 1.5550\n",
      "updated.... average c-index = 0.5539\n",
      "itr: 8000 | loss: 1.8348\n",
      "itr: 9000 | loss: 1.6144\n",
      "itr: 10000 | loss: 2.2173\n",
      "itr: 11000 | loss: 2.0753\n",
      "itr: 12000 | loss: 1.7641\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5642c3a98ca5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mPARAMETERS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_curr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMASK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMISSING\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPARAMETERS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mU:\\Hieu\\CARDIA_longi_project\\Dynamic-DeepHit-master\\class_DeepLongitudinal.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, DATA, MASK, MISSING, PARAMETERS, keep_prob, lr_train)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mx_mi_mb\u001b[0m\u001b[1;33m)\u001b[0m                 \u001b[1;33m=\u001b[0m \u001b[0mMISSING\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0mPARAMETERS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m         return self.sess.run([self.solver, self.LOSS_TOTAL], \n\u001b[0m\u001b[0;32m    307\u001b[0m                              feed_dict={self.x:x_mb, self.x_mi: x_mi_mb, self.k:k_mb, self.t:t_mb,\n\u001b[0;32m    308\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_mask1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mm1_mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_mask2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mm2_mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_mask3\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mm3_mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1369\u001b[0m                            run_metadata)\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1373\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1360\u001b[0m                                       target_list, run_metadata)\n\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1449\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1450\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1451\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m                                             run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Trained with number of iteration 25000 -> 50000\n",
    "\n",
    "fold = 1\n",
    "print('FOLD '+str(fold) + '...')\n",
    "\n",
    "##### get training, testing, and validation data:\n",
    "df_train = df.loc[df['ID'].isin(trainingid_all.iloc[:,fold])]\n",
    "df_val = df.loc[df['ID'].isin(validationid_all.iloc[:,fold])]\n",
    "df_test = df.loc[df['ID'].isin(testingid_all.iloc[:,fold])]\n",
    "\n",
    "# ### TRAINING-TESTING SPLIT in the format suitable for this network\n",
    "\n",
    "(x_dim, x_dim_cont, x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi) = impt.import_dataset(df_ = df_test)\n",
    "(x_dim, x_dim_cont, x_dim_bin), (va_data, va_time, va_label), (va_mask1, va_mask2, va_mask3), (va_data_mi) = impt.import_dataset(df_ = df_val)\n",
    "(x_dim, x_dim_cont, x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi) = impt.import_dataset(df_ = df_train)\n",
    "\n",
    "if boost_mode == 'ON':\n",
    "    tr_data, tr_data_mi, tr_time, tr_label, tr_mask1, tr_mask2, tr_mask3 = f_get_boosted_trainset(tr_data, tr_data_mi, tr_time, tr_label, tr_mask1, tr_mask2, tr_mask3)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### CREATE AND TRAIN NETWORK:\n",
    "# tf.reset_default_graph()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dyanmic-DeepHit\", input_dims, network_settings)\n",
    "# saver = tf.train.Saver()\n",
    "saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "### TRAINING - BURN-IN\n",
    "if burn_in_mode == 'ON':\n",
    "    print( \"BURN-IN TRAINING ...\")\n",
    "    for itr in range(iteration_burn_in):\n",
    "        x_mb, x_mi_mb, k_mb, t_mb, m1_mb, m2_mb, m3_mb = f_get_minibatch(mb_size, tr_data, tr_data_mi, tr_label, tr_time, tr_mask1, tr_mask2, tr_mask3)\n",
    "        DATA = (x_mb, k_mb, t_mb)\n",
    "        MISSING = (x_mi_mb)\n",
    "\n",
    "        _, loss_curr = model.train_burn_in(DATA, MISSING, keep_prob, lr_train)\n",
    "\n",
    "        if (itr+1)%1000 == 0:\n",
    "            print('itr: {:04d} | loss: {:.4f}'.format(itr+1, loss_curr))\n",
    "\n",
    "\n",
    "### TRAINING - MAIN\n",
    "print( \"MAIN TRAINING ...\")\n",
    "min_valid = 0.5\n",
    "\n",
    "for itr in range(iteration):\n",
    "    x_mb, x_mi_mb, k_mb, t_mb, m1_mb, m2_mb, m3_mb = f_get_minibatch(mb_size, tr_data, tr_data_mi, tr_label, tr_time, tr_mask1, tr_mask2, tr_mask3)\n",
    "    DATA = (x_mb, k_mb, t_mb)\n",
    "    MASK = (m1_mb, m2_mb, m3_mb)\n",
    "    MISSING = (x_mi_mb)\n",
    "    PARAMETERS = (alpha, beta, gamma)\n",
    "\n",
    "    _, loss_curr = model.train(DATA, MASK, MISSING, PARAMETERS, keep_prob, lr_train)\n",
    "\n",
    "    if (itr+1)%1000 == 0:\n",
    "        print('itr: {:04d} | loss: {:.4f}'.format(itr+1, loss_curr))\n",
    "\n",
    "    ### VALIDATION  (based on average C-index of our interest)\n",
    "    if (itr+1)%1000 == 0:        \n",
    "        risk_all = f_get_risk_predictions(sess, model, va_data, va_data_mi, pred_time, eval_time)\n",
    "\n",
    "        for p, p_time in enumerate(pred_time):\n",
    "            pred_horizon = int(p_time)\n",
    "            val_result1 = np.zeros([num_Event, len(eval_time)])\n",
    "\n",
    "            for t, t_time in enumerate(eval_time):                \n",
    "                eval_horizon = int(t_time) + pred_horizon\n",
    "                for k in range(num_Event):\n",
    "                    val_result1[k, t] = c_index(risk_all[k][:, p, t], va_time, (va_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "\n",
    "            if p == 0:\n",
    "                val_final1 = val_result1\n",
    "            else:\n",
    "                val_final1 = np.append(val_final1, val_result1, axis=0)\n",
    "\n",
    "        tmp_valid = np.mean(val_final1)\n",
    "\n",
    "        if tmp_valid >  min_valid:\n",
    "            min_valid = tmp_valid\n",
    "            saver.save(sess, file_path + '/model')\n",
    "            print( 'updated.... average c-index = ' + str('%.4f' %(tmp_valid)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### PREDICTION ON TEST SET               \n",
    "#saver.restore(sess, file_path + '/model')\n",
    "\n",
    "risk_all = f_get_risk_predictions(sess, model, te_data, te_data_mi, pred_time, eval_time)\n",
    "\n",
    "for p, p_time in enumerate(pred_time):\n",
    "    pred_horizon = int(p_time)\n",
    "    result1, result2 = np.zeros([num_Event, len(eval_time)]), np.zeros([num_Event, len(eval_time)])\n",
    "\n",
    "    for t, t_time in enumerate(eval_time):                \n",
    "        eval_horizon = int(t_time) + pred_horizon\n",
    "        for k in range(num_Event):\n",
    "            result1[k, t] = c_index(risk_all[k][:, p, t], te_time, (te_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "            result2[k, t] = brier_score(risk_all[k][:, p, t], te_time, (te_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "\n",
    "    if p == 0:\n",
    "        final1, final2 = result1, result2\n",
    "    else:\n",
    "        final1, final2 = np.append(final1, result1, axis=0), np.append(final2, result2, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### PRINT PERFORMANCE RESULTS\n",
    "row_header = []\n",
    "for p_time in pred_time:\n",
    "    for t in range(num_Event):\n",
    "        row_header.append('pred_time {}: event_{}'.format(p_time,k+1))\n",
    "\n",
    "col_header = []\n",
    "for t_time in eval_time:\n",
    "    col_header.append('eval_time {}'.format(t_time))\n",
    "\n",
    "\n",
    "# c-index result\n",
    "df1 = pd.DataFrame(final1, index = row_header, columns=col_header)\n",
    "\n",
    "# brier-score result\n",
    "df2 = pd.DataFrame(final2, index = row_header, columns=col_header)\n",
    "\n",
    "print('========================================================')\n",
    "print('--------------------------------------------------------')\n",
    "print('- C-INDEX: ')\n",
    "print(df1)\n",
    "print('--------------------------------------------------------')\n",
    "print('- BRIER-SCORE: ')\n",
    "print(df2)\n",
    "print('========================================================')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### SAVE C-INDEX, BRIER SCORE, and PREDICTED PROB RISK ON TEST SET\n",
    "actual_fold = fold+1\n",
    "work_dir = 'U:/Hieu/CARDIA_longi_project'\n",
    "savedir = os.path.join(work_dir,'rdata_files/dynamic_deephit_ascvd_var_y15_fold_'+str(actual_fold)+'/')\n",
    "try: \n",
    "    os.makedirs(savedir)\n",
    "except OSError:\n",
    "    if not os.path.isdir(savedir):\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "c_over_time = df1.iloc[:,0]\n",
    "# c_over_time.to_csv(savedir+'/c_index.csv', index = None, header = True)\n",
    "\n",
    "brier_over_time = df2.iloc[:,0]\n",
    "# brier_over_time.to_csv(savedir+'/brier_score.csv', index = None, header = True)\n",
    "\n",
    "\n",
    "\n",
    "prob_risk_test_df = pd.DataFrame(risk_all[0][:,:,0])\n",
    "prob_risk_test_df.columns = pred_time\n",
    "prob_risk_test_df.insert(loc=0, column='ID', value=np.unique(df_test['ID']))\n",
    "# prob_risk_test_df.to_csv(savedir+'/prob_risk_test.csv', index = None, header = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING AND TESTING IN LOOP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0...\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "BURN-IN TRAINING ...\n",
      "itr: 1000 | loss: 2.8584\n",
      "itr: 2000 | loss: 1.5222\n",
      "itr: 3000 | loss: 1.4856\n",
      "MAIN TRAINING ...\n",
      "itr: 1000 | loss: 1.6830\n",
      "updated.... average c-index = 0.5393\n",
      "itr: 2000 | loss: 2.1512\n",
      "updated.... average c-index = 0.5687\n",
      "itr: 3000 | loss: 1.6108\n",
      "itr: 4000 | loss: 2.1840\n",
      "itr: 5000 | loss: 1.5090\n",
      "updated.... average c-index = 0.5795\n",
      "itr: 6000 | loss: 1.0950\n",
      "itr: 7000 | loss: 1.5397\n",
      "updated.... average c-index = 0.5939\n",
      "itr: 8000 | loss: 1.7656\n",
      "itr: 9000 | loss: 1.7197\n",
      "itr: 10000 | loss: 1.1308\n",
      "itr: 11000 | loss: 1.0158\n",
      "itr: 12000 | loss: 1.2947\n",
      "itr: 13000 | loss: 2.0361\n",
      "itr: 14000 | loss: 1.6770\n",
      "itr: 15000 | loss: 1.8374\n",
      "itr: 16000 | loss: 1.9535\n",
      "itr: 17000 | loss: 1.3050\n",
      "itr: 18000 | loss: 1.7168\n",
      "itr: 19000 | loss: 1.2055\n",
      "itr: 20000 | loss: 1.1645\n",
      "itr: 21000 | loss: 1.2483\n",
      "itr: 22000 | loss: 1.0601\n",
      "itr: 23000 | loss: 1.8196\n",
      "itr: 24000 | loss: 1.1338\n",
      "itr: 25000 | loss: 1.0670\n",
      "itr: 26000 | loss: 2.3029\n",
      "itr: 27000 | loss: 2.1697\n",
      "itr: 28000 | loss: 1.2295\n",
      "itr: 29000 | loss: 1.7366\n",
      "itr: 30000 | loss: 2.1470\n",
      "itr: 31000 | loss: 1.4283\n",
      "itr: 32000 | loss: 1.6202\n",
      "itr: 33000 | loss: 1.0695\n",
      "itr: 34000 | loss: 1.4065\n",
      "itr: 35000 | loss: 1.2208\n",
      "itr: 36000 | loss: 1.6331\n",
      "itr: 37000 | loss: 1.6557\n",
      "itr: 38000 | loss: 2.6583\n",
      "itr: 39000 | loss: 1.2525\n",
      "itr: 40000 | loss: 1.9560\n",
      "itr: 41000 | loss: 1.2297\n",
      "itr: 42000 | loss: 1.3697\n",
      "itr: 43000 | loss: 0.8127\n",
      "itr: 44000 | loss: 2.1233\n",
      "itr: 45000 | loss: 1.6095\n",
      "itr: 46000 | loss: 1.6214\n",
      "itr: 47000 | loss: 1.3494\n",
      "itr: 48000 | loss: 0.8145\n",
      "itr: 49000 | loss: 1.2273\n",
      "itr: 50000 | loss: 1.2910\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.814867\n",
      "pred_time 17: event_1     0.814867\n",
      "pred_time 18: event_1     0.660563\n",
      "pred_time 19: event_1     0.647192\n",
      "pred_time 20: event_1     0.725344\n",
      "pred_time 21: event_1     0.749409\n",
      "pred_time 22: event_1     0.749051\n",
      "pred_time 23: event_1     0.770865\n",
      "pred_time 24: event_1     0.794614\n",
      "pred_time 25: event_1     0.802449\n",
      "pred_time 26: event_1     0.804552\n",
      "pred_time 27: event_1     0.801373\n",
      "pred_time 28: event_1     0.789532\n",
      "pred_time 29: event_1     0.791960\n",
      "pred_time 30: event_1     0.809289\n",
      "pred_time 31: event_1     0.756632\n",
      "pred_time 32: event_1     0.749380\n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.000093\n",
      "pred_time 17: event_1     0.000320\n",
      "pred_time 18: event_1     0.000482\n",
      "pred_time 19: event_1     0.000611\n",
      "pred_time 20: event_1     0.001083\n",
      "pred_time 21: event_1     0.001229\n",
      "pred_time 22: event_1     0.001689\n",
      "pred_time 23: event_1     0.001981\n",
      "pred_time 24: event_1     0.002282\n",
      "pred_time 25: event_1     0.002585\n",
      "pred_time 26: event_1     0.002887\n",
      "pred_time 27: event_1     0.003266\n",
      "pred_time 28: event_1     0.003580\n",
      "pred_time 29: event_1     0.003939\n",
      "pred_time 30: event_1     0.004463\n",
      "pred_time 31: event_1     0.004911\n",
      "pred_time 32: event_1     0.038721\n",
      "========================================================\n",
      "FOLD 1...\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BURN-IN TRAINING ...\n",
      "itr: 1000 | loss: 2.8194\n",
      "itr: 2000 | loss: 1.6141\n",
      "itr: 3000 | loss: 1.5001\n",
      "MAIN TRAINING ...\n",
      "itr: 1000 | loss: 1.6779\n",
      "updated.... average c-index = 0.5151\n",
      "itr: 2000 | loss: 1.7990\n",
      "updated.... average c-index = 0.5290\n",
      "itr: 3000 | loss: 1.5998\n",
      "itr: 4000 | loss: 1.1896\n",
      "updated.... average c-index = 0.5379\n",
      "itr: 5000 | loss: 1.3940\n",
      "itr: 6000 | loss: 1.4818\n",
      "updated.... average c-index = 0.5544\n",
      "itr: 7000 | loss: 1.2846\n",
      "itr: 8000 | loss: 1.4833\n",
      "itr: 9000 | loss: 1.8510\n",
      "updated.... average c-index = 0.5583\n",
      "itr: 10000 | loss: 2.0098\n",
      "itr: 11000 | loss: 1.8352\n",
      "itr: 12000 | loss: 1.3408\n",
      "itr: 13000 | loss: 1.3334\n",
      "itr: 14000 | loss: 1.4397\n",
      "itr: 15000 | loss: 1.5712\n",
      "itr: 16000 | loss: 1.6061\n",
      "itr: 17000 | loss: 1.0058\n",
      "itr: 18000 | loss: 1.9418\n",
      "itr: 19000 | loss: 1.2793\n",
      "itr: 20000 | loss: 1.0496\n",
      "itr: 21000 | loss: 1.9895\n",
      "itr: 22000 | loss: 0.7993\n",
      "itr: 23000 | loss: 1.2211\n",
      "itr: 24000 | loss: 1.5958\n",
      "itr: 25000 | loss: 1.3495\n",
      "itr: 26000 | loss: 1.9995\n",
      "itr: 27000 | loss: 1.5651\n",
      "itr: 28000 | loss: 1.7062\n",
      "itr: 29000 | loss: 0.9853\n",
      "itr: 30000 | loss: 0.9732\n",
      "itr: 31000 | loss: 2.2298\n",
      "itr: 32000 | loss: 0.9124\n",
      "itr: 33000 | loss: 2.0045\n",
      "itr: 34000 | loss: 2.3011\n",
      "itr: 35000 | loss: 1.2713\n",
      "itr: 36000 | loss: 2.0156\n",
      "itr: 37000 | loss: 1.3314\n",
      "itr: 38000 | loss: 1.6930\n",
      "itr: 39000 | loss: 1.2660\n",
      "itr: 40000 | loss: 1.4681\n",
      "itr: 41000 | loss: 1.5995\n",
      "itr: 42000 | loss: 1.4347\n",
      "itr: 43000 | loss: 1.4758\n",
      "itr: 44000 | loss: 1.3114\n",
      "itr: 45000 | loss: 1.3265\n",
      "itr: 46000 | loss: 1.3525\n",
      "itr: 47000 | loss: 1.6530\n",
      "itr: 48000 | loss: 1.9012\n",
      "itr: 49000 | loss: 1.5065\n",
      "itr: 50000 | loss: 1.3195\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1    -1.000000\n",
      "pred_time 17: event_1     0.300283\n",
      "pred_time 18: event_1     0.298867\n",
      "pred_time 19: event_1     0.699395\n",
      "pred_time 20: event_1     0.761950\n",
      "pred_time 21: event_1     0.777798\n",
      "pred_time 22: event_1     0.793562\n",
      "pred_time 23: event_1     0.795478\n",
      "pred_time 24: event_1     0.793547\n",
      "pred_time 25: event_1     0.787686\n",
      "pred_time 26: event_1     0.786265\n",
      "pred_time 27: event_1     0.786747\n",
      "pred_time 28: event_1     0.758663\n",
      "pred_time 29: event_1     0.754835\n",
      "pred_time 30: event_1     0.751396\n",
      "pred_time 31: event_1     0.733585\n",
      "pred_time 32: event_1     0.729357\n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.000010\n",
      "pred_time 17: event_1     0.000230\n",
      "pred_time 18: event_1     0.000303\n",
      "pred_time 19: event_1     0.000574\n",
      "pred_time 20: event_1     0.000865\n",
      "pred_time 21: event_1     0.001012\n",
      "pred_time 22: event_1     0.001386\n",
      "pred_time 23: event_1     0.001656\n",
      "pred_time 24: event_1     0.001863\n",
      "pred_time 25: event_1     0.002149\n",
      "pred_time 26: event_1     0.002362\n",
      "pred_time 27: event_1     0.002434\n",
      "pred_time 28: event_1     0.002651\n",
      "pred_time 29: event_1     0.003218\n",
      "pred_time 30: event_1     0.003926\n",
      "pred_time 31: event_1     0.004351\n",
      "pred_time 32: event_1     0.035750\n",
      "========================================================\n",
      "FOLD 2...\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BURN-IN TRAINING ...\n",
      "itr: 1000 | loss: 2.2936\n",
      "itr: 2000 | loss: 1.8271\n",
      "itr: 3000 | loss: 1.9363\n",
      "MAIN TRAINING ...\n",
      "itr: 1000 | loss: 1.6016\n",
      "updated.... average c-index = 0.5751\n",
      "itr: 2000 | loss: 1.7979\n",
      "updated.... average c-index = 0.5945\n",
      "itr: 3000 | loss: 2.0241\n",
      "updated.... average c-index = 0.6040\n",
      "itr: 4000 | loss: 1.5603\n",
      "itr: 5000 | loss: 1.3110\n",
      "updated.... average c-index = 0.6069\n",
      "itr: 6000 | loss: 1.3538\n",
      "updated.... average c-index = 0.6124\n",
      "itr: 7000 | loss: 1.6789\n",
      "itr: 8000 | loss: 1.1816\n",
      "itr: 9000 | loss: 0.8732\n",
      "updated.... average c-index = 0.6158\n",
      "itr: 10000 | loss: 1.9292\n",
      "updated.... average c-index = 0.6177\n",
      "itr: 11000 | loss: 1.5237\n",
      "itr: 12000 | loss: 1.4024\n",
      "itr: 13000 | loss: 1.0066\n",
      "itr: 14000 | loss: 0.8884\n",
      "updated.... average c-index = 0.6201\n",
      "itr: 15000 | loss: 1.2418\n",
      "itr: 16000 | loss: 1.0404\n",
      "updated.... average c-index = 0.6237\n",
      "itr: 17000 | loss: 1.7092\n",
      "itr: 18000 | loss: 1.1628\n",
      "updated.... average c-index = 0.6239\n",
      "itr: 19000 | loss: 1.9254\n",
      "updated.... average c-index = 0.6243\n",
      "itr: 20000 | loss: 1.8644\n",
      "itr: 21000 | loss: 1.1379\n",
      "itr: 22000 | loss: 1.5878\n",
      "itr: 23000 | loss: 1.7056\n",
      "itr: 24000 | loss: 1.4581\n",
      "itr: 25000 | loss: 1.3185\n",
      "itr: 26000 | loss: 1.9003\n",
      "updated.... average c-index = 0.6302\n",
      "itr: 27000 | loss: 1.2759\n",
      "updated.... average c-index = 0.6329\n",
      "itr: 28000 | loss: 1.4138\n",
      "itr: 29000 | loss: 1.2630\n",
      "itr: 30000 | loss: 1.2999\n",
      "itr: 31000 | loss: 1.4670\n",
      "itr: 32000 | loss: 1.0601\n",
      "itr: 33000 | loss: 1.3550\n",
      "itr: 34000 | loss: 2.0435\n",
      "itr: 35000 | loss: 1.1718\n",
      "itr: 36000 | loss: 1.6238\n",
      "itr: 37000 | loss: 1.1163\n",
      "itr: 38000 | loss: 1.5783\n",
      "itr: 39000 | loss: 1.2702\n",
      "itr: 40000 | loss: 0.9264\n",
      "itr: 41000 | loss: 1.0665\n",
      "itr: 42000 | loss: 1.3407\n",
      "itr: 43000 | loss: 1.1438\n",
      "itr: 44000 | loss: 1.3568\n",
      "itr: 45000 | loss: 1.1252\n",
      "itr: 46000 | loss: 1.0582\n",
      "itr: 47000 | loss: 1.1028\n",
      "itr: 48000 | loss: 1.3294\n",
      "itr: 49000 | loss: 1.4001\n",
      "itr: 50000 | loss: 1.4227\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1    -1.000000\n",
      "pred_time 17: event_1     0.477337\n",
      "pred_time 18: event_1     0.662877\n",
      "pred_time 19: event_1     0.701376\n",
      "pred_time 20: event_1     0.697106\n",
      "pred_time 21: event_1     0.704057\n",
      "pred_time 22: event_1     0.673982\n",
      "pred_time 23: event_1     0.730999\n",
      "pred_time 24: event_1     0.745123\n",
      "pred_time 25: event_1     0.760936\n",
      "pred_time 26: event_1     0.776277\n",
      "pred_time 27: event_1     0.747005\n",
      "pred_time 28: event_1     0.742292\n",
      "pred_time 29: event_1     0.763642\n",
      "pred_time 30: event_1     0.765799\n",
      "pred_time 31: event_1     0.752902\n",
      "pred_time 32: event_1     0.739502\n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.000012\n",
      "pred_time 17: event_1     0.000221\n",
      "pred_time 18: event_1     0.000461\n",
      "pred_time 19: event_1     0.000579\n",
      "pred_time 20: event_1     0.000935\n",
      "pred_time 21: event_1     0.001444\n",
      "pred_time 22: event_1     0.001532\n",
      "pred_time 23: event_1     0.001796\n",
      "pred_time 24: event_1     0.002075\n",
      "pred_time 25: event_1     0.002218\n",
      "pred_time 26: event_1     0.002432\n",
      "pred_time 27: event_1     0.002787\n",
      "pred_time 28: event_1     0.003145\n",
      "pred_time 29: event_1     0.003786\n",
      "pred_time 30: event_1     0.003925\n",
      "pred_time 31: event_1     0.004211\n",
      "pred_time 32: event_1     0.034376\n",
      "========================================================\n",
      "FOLD 3...\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BURN-IN TRAINING ...\n",
      "itr: 1000 | loss: 2.7973\n",
      "itr: 2000 | loss: 1.8508\n",
      "itr: 3000 | loss: 1.2319\n",
      "MAIN TRAINING ...\n",
      "itr: 1000 | loss: 2.8670\n",
      "updated.... average c-index = 0.5705\n",
      "itr: 2000 | loss: 1.4811\n",
      "updated.... average c-index = 0.5983\n",
      "itr: 3000 | loss: 1.4825\n",
      "updated.... average c-index = 0.6095\n",
      "itr: 4000 | loss: 1.7230\n",
      "updated.... average c-index = 0.6183\n",
      "itr: 5000 | loss: 1.2094\n",
      "updated.... average c-index = 0.6264\n",
      "itr: 6000 | loss: 1.4561\n",
      "updated.... average c-index = 0.6299\n",
      "itr: 7000 | loss: 1.4100\n",
      "updated.... average c-index = 0.6302\n",
      "itr: 8000 | loss: 1.4861\n",
      "updated.... average c-index = 0.6450\n",
      "itr: 9000 | loss: 2.6927\n",
      "updated.... average c-index = 0.6459\n",
      "itr: 10000 | loss: 1.1787\n",
      "updated.... average c-index = 0.6497\n",
      "itr: 11000 | loss: 1.4491\n",
      "itr: 12000 | loss: 0.8047\n",
      "itr: 13000 | loss: 0.8246\n",
      "itr: 14000 | loss: 1.1870\n",
      "itr: 15000 | loss: 1.3092\n",
      "itr: 16000 | loss: 2.2130\n",
      "itr: 17000 | loss: 1.2782\n",
      "itr: 18000 | loss: 1.0504\n",
      "itr: 19000 | loss: 1.3346\n",
      "itr: 20000 | loss: 1.9697\n",
      "itr: 21000 | loss: 1.5782\n",
      "itr: 22000 | loss: 1.9043\n",
      "itr: 23000 | loss: 2.0260\n",
      "itr: 24000 | loss: 2.3923\n",
      "itr: 25000 | loss: 1.8224\n",
      "itr: 26000 | loss: 1.3989\n",
      "itr: 27000 | loss: 1.3638\n",
      "itr: 28000 | loss: 1.0447\n",
      "itr: 29000 | loss: 1.2452\n",
      "itr: 30000 | loss: 1.9440\n",
      "itr: 31000 | loss: 1.3436\n",
      "itr: 32000 | loss: 1.4063\n",
      "itr: 33000 | loss: 1.3668\n",
      "itr: 34000 | loss: 1.3688\n",
      "itr: 35000 | loss: 1.9438\n",
      "itr: 36000 | loss: 2.0930\n",
      "itr: 37000 | loss: 2.0479\n",
      "itr: 38000 | loss: 1.5723\n",
      "itr: 39000 | loss: 1.5792\n",
      "itr: 40000 | loss: 1.4692\n",
      "itr: 41000 | loss: 0.9890\n",
      "itr: 42000 | loss: 1.5575\n",
      "itr: 43000 | loss: 1.3862\n",
      "itr: 44000 | loss: 1.3527\n",
      "itr: 45000 | loss: 1.2954\n",
      "itr: 46000 | loss: 1.3170\n",
      "itr: 47000 | loss: 1.6955\n",
      "itr: 48000 | loss: 1.1113\n",
      "itr: 49000 | loss: 1.6250\n",
      "itr: 50000 | loss: 1.8509\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.893918\n",
      "pred_time 17: event_1     0.932011\n",
      "pred_time 18: event_1     0.951796\n",
      "pred_time 19: event_1     0.949692\n",
      "pred_time 20: event_1     0.949929\n",
      "pred_time 21: event_1     0.951115\n",
      "pred_time 22: event_1     0.904898\n",
      "pred_time 23: event_1     0.841002\n",
      "pred_time 24: event_1     0.824668\n",
      "pred_time 25: event_1     0.804424\n",
      "pred_time 26: event_1     0.824067\n",
      "pred_time 27: event_1     0.808478\n",
      "pred_time 28: event_1     0.792489\n",
      "pred_time 29: event_1     0.813697\n",
      "pred_time 30: event_1     0.794525\n",
      "pred_time 31: event_1     0.812735\n",
      "pred_time 32: event_1     0.808383\n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.000149\n",
      "pred_time 17: event_1     0.000228\n",
      "pred_time 18: event_1     0.000311\n",
      "pred_time 19: event_1     0.000718\n",
      "pred_time 20: event_1     0.000868\n",
      "pred_time 21: event_1     0.001017\n",
      "pred_time 22: event_1     0.001455\n",
      "pred_time 23: event_1     0.001645\n",
      "pred_time 24: event_1     0.001788\n",
      "pred_time 25: event_1     0.002142\n",
      "pred_time 26: event_1     0.002497\n",
      "pred_time 27: event_1     0.002639\n",
      "pred_time 28: event_1     0.002995\n",
      "pred_time 29: event_1     0.003766\n",
      "pred_time 30: event_1     0.003917\n",
      "pred_time 31: event_1     0.004474\n",
      "pred_time 32: event_1     0.036965\n",
      "========================================================\n",
      "FOLD 4...\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BURN-IN TRAINING ...\n",
      "itr: 1000 | loss: 2.3391\n",
      "itr: 2000 | loss: 1.9675\n",
      "itr: 3000 | loss: 1.3501\n",
      "MAIN TRAINING ...\n",
      "itr: 1000 | loss: 2.4507\n",
      "updated.... average c-index = 0.6110\n",
      "itr: 2000 | loss: 1.7542\n",
      "updated.... average c-index = 0.6214\n",
      "itr: 3000 | loss: 2.2556\n",
      "updated.... average c-index = 0.6366\n",
      "itr: 4000 | loss: 1.5167\n",
      "itr: 5000 | loss: 1.2767\n",
      "updated.... average c-index = 0.6442\n",
      "itr: 6000 | loss: 1.6495\n",
      "itr: 7000 | loss: 2.4489\n",
      "updated.... average c-index = 0.6472\n",
      "itr: 8000 | loss: 1.6025\n",
      "updated.... average c-index = 0.6561\n",
      "itr: 9000 | loss: 1.7718\n",
      "itr: 10000 | loss: 1.2741\n",
      "itr: 11000 | loss: 1.6800\n",
      "updated.... average c-index = 0.6593\n",
      "itr: 12000 | loss: 1.9063\n",
      "updated.... average c-index = 0.6613\n",
      "itr: 13000 | loss: 1.5564\n",
      "itr: 14000 | loss: 0.8851\n",
      "itr: 15000 | loss: 1.4811\n",
      "itr: 16000 | loss: 1.7142\n",
      "itr: 17000 | loss: 1.6077\n",
      "itr: 18000 | loss: 1.5643\n",
      "itr: 19000 | loss: 1.6827\n",
      "itr: 20000 | loss: 1.1064\n",
      "updated.... average c-index = 0.6696\n",
      "itr: 21000 | loss: 0.7816\n",
      "itr: 22000 | loss: 1.5401\n",
      "itr: 23000 | loss: 1.0384\n",
      "updated.... average c-index = 0.6697\n",
      "itr: 24000 | loss: 1.7327\n",
      "itr: 25000 | loss: 1.8292\n",
      "itr: 26000 | loss: 1.7226\n",
      "itr: 27000 | loss: 1.1021\n",
      "updated.... average c-index = 0.6743\n",
      "itr: 28000 | loss: 1.6184\n",
      "updated.... average c-index = 0.6775\n",
      "itr: 29000 | loss: 1.4516\n",
      "updated.... average c-index = 0.6857\n",
      "itr: 30000 | loss: 0.9951\n",
      "itr: 31000 | loss: 1.2172\n",
      "updated.... average c-index = 0.6861\n",
      "itr: 32000 | loss: 1.5404\n",
      "itr: 33000 | loss: 1.7129\n",
      "itr: 34000 | loss: 1.2789\n",
      "itr: 35000 | loss: 1.4696\n",
      "itr: 36000 | loss: 1.1957\n",
      "itr: 37000 | loss: 1.6491\n",
      "itr: 38000 | loss: 1.3092\n",
      "itr: 39000 | loss: 1.5689\n",
      "itr: 40000 | loss: 2.2915\n",
      "updated.... average c-index = 0.6882\n",
      "itr: 41000 | loss: 1.7751\n",
      "itr: 42000 | loss: 1.1213\n",
      "itr: 43000 | loss: 1.3614\n",
      "itr: 44000 | loss: 1.7957\n",
      "itr: 45000 | loss: 0.8374\n",
      "itr: 46000 | loss: 1.3725\n",
      "itr: 47000 | loss: 1.3468\n",
      "itr: 48000 | loss: 1.2491\n",
      "itr: 49000 | loss: 0.5794\n",
      "itr: 50000 | loss: 1.4891\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1    -1.000000\n",
      "pred_time 17: event_1     0.436402\n",
      "pred_time 18: event_1     0.650687\n",
      "pred_time 19: event_1     0.710675\n",
      "pred_time 20: event_1     0.711484\n",
      "pred_time 21: event_1     0.724896\n",
      "pred_time 22: event_1     0.734291\n",
      "pred_time 23: event_1     0.686453\n",
      "pred_time 24: event_1     0.696883\n",
      "pred_time 25: event_1     0.695975\n",
      "pred_time 26: event_1     0.679600\n",
      "pred_time 27: event_1     0.684760\n",
      "pred_time 28: event_1     0.688021\n",
      "pred_time 29: event_1     0.691118\n",
      "pred_time 30: event_1     0.715529\n",
      "pred_time 31: event_1     0.712532\n",
      "pred_time 32: event_1     0.720015\n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.000002\n",
      "pred_time 17: event_1     0.000169\n",
      "pred_time 18: event_1     0.000624\n",
      "pred_time 19: event_1     0.000844\n",
      "pred_time 20: event_1     0.001080\n",
      "pred_time 21: event_1     0.001468\n",
      "pred_time 22: event_1     0.001695\n",
      "pred_time 23: event_1     0.002293\n",
      "pred_time 24: event_1     0.002368\n",
      "pred_time 25: event_1     0.002597\n",
      "pred_time 26: event_1     0.002976\n",
      "pred_time 27: event_1     0.003432\n",
      "pred_time 28: event_1     0.003969\n",
      "pred_time 29: event_1     0.004114\n",
      "pred_time 30: event_1     0.004491\n",
      "pred_time 31: event_1     0.004794\n",
      "pred_time 32: event_1     0.036596\n",
      "========================================================\n",
      "FOLD 5...\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BURN-IN TRAINING ...\n",
      "itr: 1000 | loss: 2.4221\n",
      "itr: 2000 | loss: 1.4932\n",
      "itr: 3000 | loss: 1.3467\n",
      "MAIN TRAINING ...\n",
      "itr: 1000 | loss: 2.1375\n",
      "updated.... average c-index = 0.7065\n",
      "itr: 2000 | loss: 2.1111\n",
      "updated.... average c-index = 0.7249\n",
      "itr: 3000 | loss: 1.7049\n",
      "updated.... average c-index = 0.7253\n",
      "itr: 4000 | loss: 2.7581\n",
      "updated.... average c-index = 0.7421\n",
      "itr: 5000 | loss: 3.0535\n",
      "itr: 6000 | loss: 1.7293\n",
      "updated.... average c-index = 0.7435\n",
      "itr: 7000 | loss: 1.9097\n",
      "itr: 8000 | loss: 2.2636\n",
      "itr: 9000 | loss: 1.3285\n",
      "itr: 10000 | loss: 1.7112\n",
      "itr: 11000 | loss: 2.2904\n",
      "itr: 12000 | loss: 1.8339\n",
      "itr: 13000 | loss: 1.7147\n",
      "itr: 14000 | loss: 2.2873\n",
      "itr: 15000 | loss: 2.6745\n",
      "itr: 16000 | loss: 2.1930\n",
      "itr: 17000 | loss: 1.3428\n",
      "itr: 18000 | loss: 1.6580\n",
      "itr: 19000 | loss: 1.3965\n",
      "itr: 20000 | loss: 1.2275\n",
      "itr: 21000 | loss: 1.5572\n",
      "itr: 22000 | loss: 1.3935\n",
      "itr: 23000 | loss: 1.4431\n",
      "itr: 24000 | loss: 1.4040\n",
      "itr: 25000 | loss: 1.7164\n",
      "itr: 26000 | loss: 1.1214\n",
      "itr: 27000 | loss: 1.8429\n",
      "itr: 28000 | loss: 1.3486\n",
      "itr: 29000 | loss: 1.2118\n",
      "itr: 30000 | loss: 1.3869\n",
      "itr: 31000 | loss: 1.7493\n",
      "itr: 32000 | loss: 0.8185\n",
      "itr: 33000 | loss: 1.5202\n",
      "itr: 34000 | loss: 1.5596\n",
      "itr: 35000 | loss: 1.9028\n",
      "itr: 36000 | loss: 1.2906\n",
      "itr: 37000 | loss: 1.2387\n",
      "itr: 38000 | loss: 1.1252\n",
      "itr: 39000 | loss: 1.8767\n",
      "itr: 40000 | loss: 1.7385\n",
      "itr: 41000 | loss: 1.0822\n",
      "itr: 42000 | loss: 1.6896\n",
      "itr: 43000 | loss: 2.0876\n",
      "itr: 44000 | loss: 1.1020\n",
      "itr: 45000 | loss: 1.4302\n",
      "itr: 46000 | loss: 1.3132\n",
      "itr: 47000 | loss: 1.1434\n",
      "itr: 48000 | loss: 1.7675\n",
      "itr: 49000 | loss: 0.9854\n",
      "itr: 50000 | loss: 1.0653\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1    -1.000000\n",
      "pred_time 17: event_1     0.432584\n",
      "pred_time 18: event_1     0.652709\n",
      "pred_time 19: event_1     0.746317\n",
      "pred_time 20: event_1     0.748537\n",
      "pred_time 21: event_1     0.675097\n",
      "pred_time 22: event_1     0.685135\n",
      "pred_time 23: event_1     0.647012\n",
      "pred_time 24: event_1     0.654250\n",
      "pred_time 25: event_1     0.655469\n",
      "pred_time 26: event_1     0.655318\n",
      "pred_time 27: event_1     0.663239\n",
      "pred_time 28: event_1     0.660471\n",
      "pred_time 29: event_1     0.689856\n",
      "pred_time 30: event_1     0.660424\n",
      "pred_time 31: event_1     0.676942\n",
      "pred_time 32: event_1     0.680852\n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.000007\n",
      "pred_time 17: event_1     0.000160\n",
      "pred_time 18: event_1     0.000487\n",
      "pred_time 19: event_1     0.000841\n",
      "pred_time 20: event_1     0.001087\n",
      "pred_time 21: event_1     0.001154\n",
      "pred_time 22: event_1     0.001552\n",
      "pred_time 23: event_1     0.002060\n",
      "pred_time 24: event_1     0.002287\n",
      "pred_time 25: event_1     0.002598\n",
      "pred_time 26: event_1     0.002746\n",
      "pred_time 27: event_1     0.003198\n",
      "pred_time 28: event_1     0.003654\n",
      "pred_time 29: event_1     0.004109\n",
      "pred_time 30: event_1     0.004485\n",
      "pred_time 31: event_1     0.004937\n",
      "pred_time 32: event_1     0.038373\n",
      "========================================================\n",
      "FOLD 6...\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BURN-IN TRAINING ...\n",
      "itr: 1000 | loss: 2.4079\n",
      "itr: 2000 | loss: 1.7935\n",
      "itr: 3000 | loss: 1.4355\n",
      "MAIN TRAINING ...\n",
      "itr: 1000 | loss: 2.2183\n",
      "updated.... average c-index = 0.6658\n",
      "itr: 2000 | loss: 2.4965\n",
      "updated.... average c-index = 0.6694\n",
      "itr: 3000 | loss: 1.6028\n",
      "updated.... average c-index = 0.6867\n",
      "itr: 4000 | loss: 0.7728\n",
      "updated.... average c-index = 0.6888\n",
      "itr: 5000 | loss: 1.2184\n",
      "updated.... average c-index = 0.6945\n",
      "itr: 6000 | loss: 1.3758\n",
      "updated.... average c-index = 0.7145\n",
      "itr: 7000 | loss: 1.7682\n",
      "itr: 8000 | loss: 1.1940\n",
      "itr: 9000 | loss: 1.4874\n",
      "updated.... average c-index = 0.7159\n",
      "itr: 10000 | loss: 1.5649\n",
      "updated.... average c-index = 0.7160\n",
      "itr: 11000 | loss: 1.4442\n",
      "itr: 12000 | loss: 1.7635\n",
      "itr: 13000 | loss: 1.2996\n",
      "itr: 14000 | loss: 1.2104\n",
      "itr: 15000 | loss: 1.2353\n",
      "updated.... average c-index = 0.7173\n",
      "itr: 16000 | loss: 1.2422\n",
      "itr: 17000 | loss: 0.9481\n",
      "itr: 18000 | loss: 1.4457\n",
      "itr: 19000 | loss: 1.4891\n",
      "itr: 20000 | loss: 1.5013\n",
      "itr: 21000 | loss: 1.2262\n",
      "itr: 22000 | loss: 1.3895\n",
      "itr: 23000 | loss: 0.8423\n",
      "itr: 24000 | loss: 1.0518\n",
      "itr: 25000 | loss: 2.0108\n",
      "itr: 26000 | loss: 0.8621\n",
      "itr: 27000 | loss: 0.9945\n",
      "itr: 28000 | loss: 1.1362\n",
      "itr: 29000 | loss: 1.4127\n",
      "itr: 30000 | loss: 1.0470\n",
      "itr: 31000 | loss: 1.3366\n",
      "itr: 32000 | loss: 0.8952\n",
      "itr: 33000 | loss: 0.9727\n",
      "itr: 34000 | loss: 0.7297\n",
      "itr: 35000 | loss: 0.7196\n",
      "itr: 36000 | loss: 1.1028\n",
      "itr: 37000 | loss: 1.3483\n",
      "itr: 38000 | loss: 1.0796\n",
      "itr: 39000 | loss: 1.9541\n",
      "itr: 40000 | loss: 1.3490\n",
      "itr: 41000 | loss: 1.6746\n",
      "itr: 42000 | loss: 1.0679\n",
      "itr: 43000 | loss: 1.5077\n",
      "itr: 44000 | loss: 1.8932\n",
      "itr: 45000 | loss: 0.8189\n",
      "itr: 46000 | loss: 1.4493\n",
      "itr: 47000 | loss: 1.2092\n",
      "itr: 48000 | loss: 1.3269\n",
      "itr: 49000 | loss: 1.1913\n",
      "itr: 50000 | loss: 0.9761\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.908062\n",
      "pred_time 17: event_1     0.906648\n",
      "pred_time 18: event_1     0.780298\n",
      "pred_time 19: event_1     0.759886\n",
      "pred_time 20: event_1     0.775166\n",
      "pred_time 21: event_1     0.757951\n",
      "pred_time 22: event_1     0.768593\n",
      "pred_time 23: event_1     0.688767\n",
      "pred_time 24: event_1     0.688857\n",
      "pred_time 25: event_1     0.704380\n",
      "pred_time 26: event_1     0.718450\n",
      "pred_time 27: event_1     0.717276\n",
      "pred_time 28: event_1     0.701720\n",
      "pred_time 29: event_1     0.723274\n",
      "pred_time 30: event_1     0.730944\n",
      "pred_time 31: event_1     0.724599\n",
      "pred_time 32: event_1     0.727060\n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.000083\n",
      "pred_time 17: event_1     0.000235\n",
      "pred_time 18: event_1     0.000331\n",
      "pred_time 19: event_1     0.000574\n",
      "pred_time 20: event_1     0.000862\n",
      "pred_time 21: event_1     0.001298\n",
      "pred_time 22: event_1     0.001622\n",
      "pred_time 23: event_1     0.001798\n",
      "pred_time 24: event_1     0.001859\n",
      "pred_time 25: event_1     0.002144\n",
      "pred_time 26: event_1     0.002644\n",
      "pred_time 27: event_1     0.002648\n",
      "pred_time 28: event_1     0.002856\n",
      "pred_time 29: event_1     0.003638\n",
      "pred_time 30: event_1     0.003919\n",
      "pred_time 31: event_1     0.004407\n",
      "pred_time 32: event_1     0.035537\n",
      "========================================================\n",
      "FOLD 7...\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BURN-IN TRAINING ...\n",
      "itr: 1000 | loss: 2.5376\n",
      "itr: 2000 | loss: 1.5836\n",
      "itr: 3000 | loss: 1.7548\n",
      "MAIN TRAINING ...\n",
      "itr: 1000 | loss: 2.0923\n",
      "updated.... average c-index = 0.5716\n",
      "itr: 2000 | loss: 1.8664\n",
      "itr: 3000 | loss: 1.1028\n",
      "updated.... average c-index = 0.5729\n",
      "itr: 4000 | loss: 2.3747\n",
      "itr: 5000 | loss: 1.6851\n",
      "updated.... average c-index = 0.5829\n",
      "itr: 6000 | loss: 1.7217\n",
      "itr: 7000 | loss: 1.0606\n",
      "itr: 8000 | loss: 1.4443\n",
      "itr: 9000 | loss: 0.9532\n",
      "itr: 10000 | loss: 1.7020\n",
      "itr: 11000 | loss: 1.2236\n",
      "itr: 12000 | loss: 2.0894\n",
      "itr: 13000 | loss: 0.9011\n",
      "itr: 14000 | loss: 1.6963\n",
      "itr: 15000 | loss: 0.9633\n",
      "itr: 16000 | loss: 1.1804\n",
      "itr: 17000 | loss: 1.4140\n",
      "itr: 18000 | loss: 1.8526\n",
      "itr: 19000 | loss: 1.1681\n",
      "itr: 20000 | loss: 1.3412\n",
      "itr: 21000 | loss: 1.1782\n",
      "itr: 22000 | loss: 1.5851\n",
      "itr: 23000 | loss: 1.4825\n",
      "itr: 24000 | loss: 1.5611\n",
      "itr: 25000 | loss: 1.2157\n",
      "itr: 26000 | loss: 1.1792\n",
      "itr: 27000 | loss: 0.9225\n",
      "itr: 28000 | loss: 1.7069\n",
      "itr: 29000 | loss: 1.3242\n",
      "itr: 30000 | loss: 0.9356\n",
      "itr: 31000 | loss: 1.3590\n",
      "itr: 32000 | loss: 0.9588\n",
      "itr: 33000 | loss: 1.8134\n",
      "itr: 34000 | loss: 1.8475\n",
      "itr: 35000 | loss: 1.2436\n",
      "itr: 36000 | loss: 0.7313\n",
      "itr: 37000 | loss: 1.7110\n",
      "itr: 38000 | loss: 2.5335\n",
      "itr: 39000 | loss: 1.2669\n",
      "itr: 40000 | loss: 1.2673\n",
      "itr: 41000 | loss: 1.6019\n",
      "itr: 42000 | loss: 0.7820\n",
      "itr: 43000 | loss: 1.5175\n",
      "itr: 44000 | loss: 1.6636\n",
      "itr: 45000 | loss: 1.2913\n",
      "itr: 46000 | loss: 1.0233\n",
      "itr: 47000 | loss: 1.0816\n",
      "itr: 48000 | loss: 0.9711\n",
      "itr: 49000 | loss: 1.2234\n",
      "itr: 50000 | loss: 1.3398\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.893918\n",
      "pred_time 17: event_1     0.791313\n",
      "pred_time 18: event_1     0.792729\n",
      "pred_time 19: event_1     0.829123\n",
      "pred_time 20: event_1     0.828714\n",
      "pred_time 21: event_1     0.830330\n",
      "pred_time 22: event_1     0.846019\n",
      "pred_time 23: event_1     0.869406\n",
      "pred_time 24: event_1     0.810530\n",
      "pred_time 25: event_1     0.784869\n",
      "pred_time 26: event_1     0.786577\n",
      "pred_time 27: event_1     0.755284\n",
      "pred_time 28: event_1     0.738198\n",
      "pred_time 29: event_1     0.728276\n",
      "pred_time 30: event_1     0.678850\n",
      "pred_time 31: event_1     0.720784\n",
      "pred_time 32: event_1     0.703754\n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.000076\n",
      "pred_time 17: event_1     0.000252\n",
      "pred_time 18: event_1     0.000324\n",
      "pred_time 19: event_1     0.000505\n",
      "pred_time 20: event_1     0.000953\n",
      "pred_time 21: event_1     0.001309\n",
      "pred_time 22: event_1     0.001484\n",
      "pred_time 23: event_1     0.001649\n",
      "pred_time 24: event_1     0.002077\n",
      "pred_time 25: event_1     0.002231\n",
      "pred_time 26: event_1     0.002436\n",
      "pred_time 27: event_1     0.002719\n",
      "pred_time 28: event_1     0.002963\n",
      "pred_time 29: event_1     0.003445\n",
      "pred_time 30: event_1     0.003930\n",
      "pred_time 31: event_1     0.004305\n",
      "pred_time 32: event_1     0.035267\n",
      "========================================================\n",
      "FOLD 8...\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "C:\\Users\\hnguye78\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BURN-IN TRAINING ...\n",
      "itr: 1000 | loss: 1.3788\n",
      "itr: 2000 | loss: 1.0792\n",
      "itr: 3000 | loss: 1.9168\n",
      "MAIN TRAINING ...\n",
      "itr: 1000 | loss: 1.4295\n",
      "itr: 2000 | loss: 1.5902\n",
      "updated.... average c-index = 0.5258\n",
      "itr: 3000 | loss: 1.7788\n",
      "updated.... average c-index = 0.5440\n",
      "itr: 4000 | loss: 1.7009\n",
      "updated.... average c-index = 0.5663\n",
      "itr: 5000 | loss: 2.0533\n",
      "itr: 6000 | loss: 2.9819\n",
      "updated.... average c-index = 0.5696\n",
      "itr: 7000 | loss: 1.8968\n",
      "updated.... average c-index = 0.5706\n",
      "itr: 8000 | loss: 1.2159\n",
      "itr: 9000 | loss: 1.1522\n",
      "itr: 10000 | loss: 2.5449\n",
      "updated.... average c-index = 0.5772\n",
      "itr: 11000 | loss: 1.0000\n",
      "itr: 12000 | loss: 1.4795\n",
      "updated.... average c-index = 0.5847\n",
      "itr: 13000 | loss: 2.2270\n",
      "updated.... average c-index = 0.5895\n",
      "itr: 14000 | loss: 1.3292\n",
      "itr: 15000 | loss: 1.2489\n",
      "itr: 16000 | loss: 1.7968\n",
      "itr: 17000 | loss: 1.4771\n",
      "itr: 18000 | loss: 1.5807\n",
      "itr: 19000 | loss: 1.2159\n",
      "itr: 20000 | loss: 1.0190\n",
      "itr: 21000 | loss: 0.9412\n",
      "itr: 22000 | loss: 1.5830\n",
      "itr: 23000 | loss: 1.9345\n",
      "itr: 24000 | loss: 2.3596\n",
      "itr: 25000 | loss: 1.0202\n",
      "itr: 26000 | loss: 1.7572\n",
      "itr: 27000 | loss: 1.5461\n",
      "itr: 28000 | loss: 1.3596\n",
      "itr: 29000 | loss: 1.6587\n",
      "itr: 30000 | loss: 1.8727\n",
      "itr: 31000 | loss: 0.8703\n",
      "itr: 32000 | loss: 1.6750\n",
      "itr: 33000 | loss: 1.5120\n",
      "itr: 34000 | loss: 1.9015\n",
      "itr: 35000 | loss: 1.5167\n",
      "itr: 36000 | loss: 1.5133\n",
      "itr: 37000 | loss: 1.3368\n",
      "itr: 38000 | loss: 1.0811\n",
      "itr: 39000 | loss: 1.6028\n",
      "itr: 40000 | loss: 1.6337\n",
      "itr: 41000 | loss: 1.6715\n",
      "itr: 42000 | loss: 1.1235\n",
      "itr: 43000 | loss: 1.6694\n",
      "itr: 44000 | loss: 1.4014\n",
      "itr: 45000 | loss: 0.6591\n",
      "itr: 46000 | loss: 1.3556\n",
      "itr: 47000 | loss: 0.9668\n",
      "itr: 48000 | loss: 1.4215\n",
      "itr: 49000 | loss: 1.6574\n",
      "itr: 50000 | loss: 1.2009\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1    -1.000000\n",
      "pred_time 17: event_1     0.700141\n",
      "pred_time 18: event_1     0.772840\n",
      "pred_time 19: event_1     0.797894\n",
      "pred_time 20: event_1     0.829060\n",
      "pred_time 21: event_1     0.832384\n",
      "pred_time 22: event_1     0.803874\n",
      "pred_time 23: event_1     0.755151\n",
      "pred_time 24: event_1     0.762944\n",
      "pred_time 25: event_1     0.780830\n",
      "pred_time 26: event_1     0.768362\n",
      "pred_time 27: event_1     0.761825\n",
      "pred_time 28: event_1     0.738376\n",
      "pred_time 29: event_1     0.730202\n",
      "pred_time 30: event_1     0.712409\n",
      "pred_time 31: event_1     0.716441\n",
      "pred_time 32: event_1     0.688575\n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 0\n",
      "pred_time 16: event_1     0.000007\n",
      "pred_time 17: event_1     0.000150\n",
      "pred_time 18: event_1     0.000567\n",
      "pred_time 19: event_1     0.000575\n",
      "pred_time 20: event_1     0.000884\n",
      "pred_time 21: event_1     0.001026\n",
      "pred_time 22: event_1     0.001093\n",
      "pred_time 23: event_1     0.001578\n",
      "pred_time 24: event_1     0.001790\n",
      "pred_time 25: event_1     0.002147\n",
      "pred_time 26: event_1     0.002368\n",
      "pred_time 27: event_1     0.002576\n",
      "pred_time 28: event_1     0.003078\n",
      "pred_time 29: event_1     0.003569\n",
      "pred_time 30: event_1     0.003932\n",
      "pred_time 31: event_1     0.004348\n",
      "pred_time 32: event_1     0.034781\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "nfolds = 10\n",
    "\n",
    "for fold in range(nfolds):\n",
    "\n",
    "\n",
    "    print('FOLD '+str(fold) + '...')\n",
    "    \n",
    "    ##### get training, testing, and validation data:\n",
    "    df_train = df.loc[df['ID'].isin(trainingid_all.iloc[:,fold])]\n",
    "    df_val = df.loc[df['ID'].isin(validationid_all.iloc[:,fold])]\n",
    "    df_test = df.loc[df['ID'].isin(testingid_all.iloc[:,fold])]\n",
    "\n",
    "    # ### TRAINING-TESTING SPLIT in the format suitable for this network\n",
    "\n",
    "    (x_dim, x_dim_cont, x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi) = impt.import_dataset(df_ = df_test)\n",
    "    (x_dim, x_dim_cont, x_dim_bin), (va_data, va_time, va_label), (va_mask1, va_mask2, va_mask3), (va_data_mi) = impt.import_dataset(df_ = df_val)\n",
    "    (x_dim, x_dim_cont, x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi) = impt.import_dataset(df_ = df_train)\n",
    "\n",
    "    if boost_mode == 'ON':\n",
    "        tr_data, tr_data_mi, tr_time, tr_label, tr_mask1, tr_mask2, tr_mask3 = f_get_boosted_trainset(tr_data, tr_data_mi, tr_time, tr_label, tr_mask1, tr_mask2, tr_mask3)  \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    ##### CREATE AND TRAIN NETWORK:\n",
    "    # tf.reset_default_graph()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    # config = tf.ConfigProto()\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "    model = Model_Longitudinal_Attention(sess, \"Dyanmic-DeepHit\", input_dims, network_settings)\n",
    "    # saver = tf.train.Saver()\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "    # sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "    ### TRAINING - BURN-IN\n",
    "    if burn_in_mode == 'ON':\n",
    "        print( \"BURN-IN TRAINING ...\")\n",
    "        for itr in range(iteration_burn_in):\n",
    "            x_mb, x_mi_mb, k_mb, t_mb, m1_mb, m2_mb, m3_mb = f_get_minibatch(mb_size, tr_data, tr_data_mi, tr_label, tr_time, tr_mask1, tr_mask2, tr_mask3)\n",
    "            DATA = (x_mb, k_mb, t_mb)\n",
    "            MISSING = (x_mi_mb)\n",
    "\n",
    "            _, loss_curr = model.train_burn_in(DATA, MISSING, keep_prob, lr_train)\n",
    "\n",
    "            if (itr+1)%1000 == 0:\n",
    "                print('itr: {:04d} | loss: {:.4f}'.format(itr+1, loss_curr))\n",
    "\n",
    "\n",
    "    ### TRAINING - MAIN\n",
    "    print( \"MAIN TRAINING ...\")\n",
    "    min_valid = 0.5\n",
    "\n",
    "    for itr in range(iteration):\n",
    "        x_mb, x_mi_mb, k_mb, t_mb, m1_mb, m2_mb, m3_mb = f_get_minibatch(mb_size, tr_data, tr_data_mi, tr_label, tr_time, tr_mask1, tr_mask2, tr_mask3)\n",
    "        DATA = (x_mb, k_mb, t_mb)\n",
    "        MASK = (m1_mb, m2_mb, m3_mb)\n",
    "        MISSING = (x_mi_mb)\n",
    "        PARAMETERS = (alpha, beta, gamma)\n",
    "\n",
    "        _, loss_curr = model.train(DATA, MASK, MISSING, PARAMETERS, keep_prob, lr_train)\n",
    "\n",
    "        if (itr+1)%1000 == 0:\n",
    "            print('itr: {:04d} | loss: {:.4f}'.format(itr+1, loss_curr))\n",
    "\n",
    "        ### VALIDATION  (based on average C-index of our interest)\n",
    "        if (itr+1)%1000 == 0:        \n",
    "            risk_all = f_get_risk_predictions(sess, model, va_data, va_data_mi, pred_time, eval_time)\n",
    "\n",
    "            for p, p_time in enumerate(pred_time):\n",
    "                pred_horizon = int(p_time)\n",
    "                val_result1 = np.zeros([num_Event, len(eval_time)])\n",
    "\n",
    "                for t, t_time in enumerate(eval_time):                \n",
    "                    eval_horizon = int(t_time) + pred_horizon\n",
    "                    for k in range(num_Event):\n",
    "                        val_result1[k, t] = c_index(risk_all[k][:, p, t], va_time, (va_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "\n",
    "                if p == 0:\n",
    "                    val_final1 = val_result1\n",
    "                else:\n",
    "                    val_final1 = np.append(val_final1, val_result1, axis=0)\n",
    "\n",
    "            tmp_valid = np.mean(val_final1)\n",
    "\n",
    "            if tmp_valid >  min_valid:\n",
    "                min_valid = tmp_valid\n",
    "                saver.save(sess, file_path + '/model')\n",
    "                print( 'updated.... average c-index = ' + str('%.4f' %(tmp_valid)))\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "         \n",
    "        \n",
    "        \n",
    "                \n",
    "    ### PREDICTION ON TEST SET               \n",
    "    #saver.restore(sess, file_path + '/model')\n",
    " \n",
    "    risk_all = f_get_risk_predictions(sess, model, te_data, te_data_mi, pred_time, eval_time)\n",
    "\n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        pred_horizon = int(p_time)\n",
    "        result1, result2 = np.zeros([num_Event, len(eval_time)]), np.zeros([num_Event, len(eval_time)])\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):                \n",
    "            eval_horizon = int(t_time) + pred_horizon\n",
    "            for k in range(num_Event):\n",
    "                result1[k, t] = c_index(risk_all[k][:, p, t], te_time, (te_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "                result2[k, t] = brier_score(risk_all[k][:, p, t], te_time, (te_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "\n",
    "        if p == 0:\n",
    "            final1, final2 = result1, result2\n",
    "        else:\n",
    "            final1, final2 = np.append(final1, result1, axis=0), np.append(final2, result2, axis=0)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### PRINT PERFORMANCE RESULTS\n",
    "    row_header = []\n",
    "    for p_time in pred_time:\n",
    "        for t in range(num_Event):\n",
    "            row_header.append('pred_time {}: event_{}'.format(p_time,k+1))\n",
    "\n",
    "    col_header = []\n",
    "    for t_time in eval_time:\n",
    "        col_header.append('eval_time {}'.format(t_time))\n",
    "\n",
    "\n",
    "    # c-index result\n",
    "    df1 = pd.DataFrame(final1, index = row_header, columns=col_header)\n",
    "\n",
    "    # brier-score result\n",
    "    df2 = pd.DataFrame(final2, index = row_header, columns=col_header)\n",
    "\n",
    "    print('========================================================')\n",
    "    print('--------------------------------------------------------')\n",
    "    print('- C-INDEX: ')\n",
    "    print(df1)\n",
    "    print('--------------------------------------------------------')\n",
    "    print('- BRIER-SCORE: ')\n",
    "    print(df2)\n",
    "    print('========================================================')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### SAVE C-INDEX, BRIER SCORE, and PREDICTED PROB RISK ON TEST SET\n",
    "    actual_fold = fold+1\n",
    "    work_dir = 'U:/Hieu/CARDIA_longi_project'\n",
    "    savedir = os.path.join(work_dir,'rdata_files/dynamic_deephit_ascvd_var_y15_fold_'+str(actual_fold)+'/')\n",
    "    try: \n",
    "        os.makedirs(savedir)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(savedir):\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "    c_over_time = df1.iloc[:,0]\n",
    "    c_over_time.to_csv(savedir+'/c_index_tuned.csv', index = None, header = True)\n",
    "\n",
    "    brier_over_time = df2.iloc[:,0]\n",
    "    brier_over_time.to_csv(savedir+'/brier_score_tuned.csv', index = None, header = True)\n",
    "\n",
    "\n",
    "\n",
    "    prob_risk_test_df = pd.DataFrame(risk_all[0][:,:,0])\n",
    "    prob_risk_test_df.columns = pred_time\n",
    "    prob_risk_test_df.insert(loc=0, column='ID', value=np.unique(df_test['ID']))\n",
    "    prob_risk_test_df.to_csv(savedir+'/prob_risk_test_tuned.csv', index = None, header = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ##### CREATE DYNAMIC-DEEPFHT NETWORK\n",
    "# # tf.reset_default_graph()\n",
    "# tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# # config = tf.ConfigProto()\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "# model = Model_Longitudinal_Attention(sess, \"Dyanmic-DeepHit\", input_dims, network_settings)\n",
    "# # saver = tf.train.Saver()\n",
    "# saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "# # sess.run(tf.global_variables_initializer())\n",
    "# sess.run(tf.compat.v1.global_variables_initializer())\n",
    " \n",
    "# ### TRAINING - BURN-IN\n",
    "# if burn_in_mode == 'ON':\n",
    "#     print( \"BURN-IN TRAINING ...\")\n",
    "#     for itr in range(iteration_burn_in):\n",
    "#         x_mb, x_mi_mb, k_mb, t_mb, m1_mb, m2_mb, m3_mb = f_get_minibatch(mb_size, tr_data, tr_data_mi, tr_label, tr_time, tr_mask1, tr_mask2, tr_mask3)\n",
    "#         DATA = (x_mb, k_mb, t_mb)\n",
    "#         MISSING = (x_mi_mb)\n",
    "\n",
    "#         _, loss_curr = model.train_burn_in(DATA, MISSING, keep_prob, lr_train)\n",
    "\n",
    "#         if (itr+1)%1000 == 0:\n",
    "#             print('itr: {:04d} | loss: {:.4f}'.format(itr+1, loss_curr))\n",
    "\n",
    "\n",
    "# ### TRAINING - MAIN\n",
    "# print( \"MAIN TRAINING ...\")\n",
    "# min_valid = 0.5\n",
    "\n",
    "# for itr in range(iteration):\n",
    "#     x_mb, x_mi_mb, k_mb, t_mb, m1_mb, m2_mb, m3_mb = f_get_minibatch(mb_size, tr_data, tr_data_mi, tr_label, tr_time, tr_mask1, tr_mask2, tr_mask3)\n",
    "#     DATA = (x_mb, k_mb, t_mb)\n",
    "#     MASK = (m1_mb, m2_mb, m3_mb)\n",
    "#     MISSING = (x_mi_mb)\n",
    "#     PARAMETERS = (alpha, beta, gamma)\n",
    "\n",
    "#     _, loss_curr = model.train(DATA, MASK, MISSING, PARAMETERS, keep_prob, lr_train)\n",
    "\n",
    "#     if (itr+1)%1000 == 0:\n",
    "#         print('itr: {:04d} | loss: {:.4f}'.format(itr+1, loss_curr))\n",
    "\n",
    "#     ### VALIDATION  (based on average C-index of our interest)\n",
    "#     if (itr+1)%1000 == 0:        \n",
    "#         risk_all = f_get_risk_predictions(sess, model, va_data, va_data_mi, pred_time, eval_time)\n",
    "        \n",
    "#         for p, p_time in enumerate(pred_time):\n",
    "#             pred_horizon = int(p_time)\n",
    "#             val_result1 = np.zeros([num_Event, len(eval_time)])\n",
    "            \n",
    "#             for t, t_time in enumerate(eval_time):                \n",
    "#                 eval_horizon = int(t_time) + pred_horizon\n",
    "#                 for k in range(num_Event):\n",
    "#                     val_result1[k, t] = c_index(risk_all[k][:, p, t], va_time, (va_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "            \n",
    "#             if p == 0:\n",
    "#                 val_final1 = val_result1\n",
    "#             else:\n",
    "#                 val_final1 = np.append(val_final1, val_result1, axis=0)\n",
    "\n",
    "#         tmp_valid = np.mean(val_final1)\n",
    "\n",
    "#         if tmp_valid >  min_valid:\n",
    "#             min_valid = tmp_valid\n",
    "#             saver.save(sess, file_path + '/model')\n",
    "#             print( 'updated.... average c-index = ' + str('%.4f' %(tmp_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "                 \n",
    "# risk_all = f_get_risk_predictions(sess, model, te_data, te_data_mi, pred_time, eval_time)\n",
    "\n",
    "# for p, p_time in enumerate(pred_time):\n",
    "#     pred_horizon = int(p_time)\n",
    "#     result1, result2 = np.zeros([num_Event, len(eval_time)]), np.zeros([num_Event, len(eval_time)])\n",
    "\n",
    "#     for t, t_time in enumerate(eval_time):                \n",
    "#         eval_horizon = int(t_time) + pred_horizon\n",
    "#         for k in range(num_Event):\n",
    "#             result1[k, t] = c_index(risk_all[k][:, p, t], te_time, (te_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "#             result2[k, t] = brier_score(risk_all[k][:, p, t], te_time, (te_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "    \n",
    "#     if p == 0:\n",
    "#         final1, final2 = result1, result2\n",
    "#     else:\n",
    "#         final1, final2 = np.append(final1, result1, axis=0), np.append(final2, result2, axis=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "# row_header = []\n",
    "# for p_time in pred_time:\n",
    "#     for t in range(num_Event):\n",
    "#         row_header.append('pred_time {}: event_{}'.format(p_time,k+1))\n",
    "            \n",
    "# col_header = []\n",
    "# for t_time in eval_time:\n",
    "#     col_header.append('eval_time {}'.format(t_time))\n",
    "\n",
    "# # c-index result\n",
    "# df1 = pd.DataFrame(final1, index = row_header, columns=col_header)\n",
    "\n",
    "# # brier-score result\n",
    "# df2 = pd.DataFrame(final2, index = row_header, columns=col_header)\n",
    "\n",
    "# ### PRINT RESULTS\n",
    "# print('========================================================')\n",
    "# print('--------------------------------------------------------')\n",
    "# print('- C-INDEX: ')\n",
    "# print(df1)\n",
    "# print('--------------------------------------------------------')\n",
    "# print('- BRIER-SCORE: ')\n",
    "# print(df2)\n",
    "# print('========================================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jupyter_contrib_nbextensions\n",
    "# !jupyter contrib nbextension install --user\n",
    "# !jupyter contrib nbextension install --sys-prefix\n",
    "# !jupyter nbextension enable varInspector/main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
